{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5425f8e3-0e45-46dd-a349-df6591997464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\user\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66135d79-ac94-4784-8ef9-af65cf8d26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\user\\anaconda3\\lib\\site-packages (0.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6376fca-52de-4b5e-bea6-856a98312149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\user\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6faa170-4b75-4c9e-8223-4c41afca1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordninja in c:\\users\\user\\anaconda3\\lib\\site-packages (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83785dfc-0b5c-42a7-9b29-9bca80254660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\user\\anaconda3\\lib\\site-packages (2.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e08fc17-696e-494f-8af3-b396b51ffc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "import wordninja\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3425d6-d8eb-415d-a552-147c837ccfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('./tiktok_google_play_reviews.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4571391-bfb6-4812-98e4-27cc2f6a3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.rename(columns={'content': 'reviews', 'score': 'rating', 'thumbsUpCount':'likes','reviewCreatedVersion': 'appversion', 'at': 'timestamp',}\n",
    "          , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9492bd50-4461-417f-a9a3-cf4a5c82ae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reviews' 'rating' 'likes' 'appversion' 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "tt.drop(columns=['reviewId' ,'userName','userImage','replyContent','repliedAt'], inplace=True)\n",
    "print(tt.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42081362-f693-42aa-9d4e-d2dfc5fa97ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 460287 entries, 0 to 460286\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   reviews     460256 non-null  object        \n",
      " 1   rating      460287 non-null  int64         \n",
      " 2   likes       460287 non-null  int64         \n",
      " 3   appversion  333953 non-null  object        \n",
      " 4   timestamp   460287 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 17.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tt['timestamp'] = pd.to_datetime(tt['timestamp'], errors='coerce',dayfirst=True)\n",
    "tt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c846a830-9375-4657-8c15-1fff07e675b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before removal:\n",
      "reviews           31\n",
      "rating             0\n",
      "likes              0\n",
      "appversion    126334\n",
      "timestamp          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after removal:\n",
      "reviews            0\n",
      "rating             0\n",
      "likes              0\n",
      "appversion    126325\n",
      "timestamp          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = tt.isnull().sum()\n",
    "\n",
    "print(\"Missing values before removal:\")\n",
    "print(missing_values)\n",
    "\n",
    "tt = tt.dropna(subset=['reviews'])\n",
    "missing_values = tt.isnull().sum()\n",
    "\n",
    "print(\"\\nMissing values after removal:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417893b-00ac-4af7-b134-bdcd7fc86596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emojis_with_text(text):\n",
    "    demojized_text = emoji.demojize(text)\n",
    "    \n",
    "    split_text = ' '.join(wordninja.split(demojized_text)) \n",
    "    \n",
    "    emoji_count = len([char for char in text if char in emoji.EMOJI_DATA])\n",
    "    \n",
    "    return split_text, emoji_count \n",
    "\n",
    "tt['reviews_original'] = tt['reviews']\n",
    "tt['reviews'], tt['emoji_count'] = zip(*tt['reviews'].apply(replace_emojis_with_text))\n",
    "\n",
    "total_emojis_replaced = tt['emoji_count'].sum()\n",
    "print(f\"Total emojis replaced: {total_emojis_replaced}\")\n",
    "\n",
    "print(tt[['reviews_original', 'reviews']].tail())\n",
    "\n",
    "tt.drop(columns=['emoji_count'], inplace=True)\n",
    "tt.drop(columns=['reviews_original'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6351a04-787f-40c3-a671-04dbdec4b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt['reviews'] = tt['reviews'].str.lower()\n",
    "tt['reviews'] = tt['reviews'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5d3b9-4703-4e71-a15e-bd858fd72991",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    try:\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning text: {text} - {e}\")\n",
    "        return text\n",
    "        \n",
    "tt['reviews_nostopwords'] = tt['reviews'].apply(remove_stopwords)\n",
    "\n",
    "print(tt[['reviews', 'reviews_nostopwords']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d982b1-650e-43f8-8574-d9fed879d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    try:\n",
    "        words = word_tokenize(text)\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        return ' '.join(lemmatized_words)\n",
    "    except Exception as e:\n",
    "        print(f\"Error lemmatizing text: {text} - {e}\")\n",
    "        return text\n",
    "        \n",
    "tt['reviews_lemmatized'] = tt['reviews_nostopwords'].apply(lemmatize_text)\n",
    "\n",
    "print(tt[['reviews_nostopwords', 'reviews_lemmatized']].head())\n",
    "tt.drop(columns=['reviews_nostopwords'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da6d50-a2b2-4521-a048-87a82418d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def remove_misspelled_words(review):\n",
    "    words = review.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    cleaned_review = ' '.join([word for word in words if word not in misspelled])\n",
    "    \n",
    "    return cleaned_review, misspelled \n",
    "\n",
    "# Apply the function to the reviews\n",
    "tt['reviews_no_misspelled_words'], tt['misspelled_words'] = zip(*tt['reviews_lemmatized'].apply(remove_misspelled_words))\n",
    "\n",
    "# Now filter rows with misspelled words\n",
    "misspelled_rows = tt[tt['misspelled_words'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "total_removed = tt['misspelled_words'].apply(len).sum()\n",
    "\n",
    "print(f\"Total words removed: {total_removed}\")\n",
    "\n",
    "all_misspelled = [word for sublist in tt['misspelled_words'] for word in sublist]\n",
    "first_100_misspelled = all_misspelled[:100]\n",
    "\n",
    "print(\"\\nSummary of the first 100 removed misspelled words:\")\n",
    "print(set(first_100_misspelled))  # Remove duplicates\n",
    "\n",
    "tt.drop(columns=['reviews_lemmatized'], inplace=True)\n",
    "tt.drop(columns=['misspelled_words'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97844169-5dd1-43c3-9c0c-3e7ffd4c2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_phrases = [\n",
    "    'tiktok', 'video', 'app', 'content','feature', 'update', 'platform', 'post','social media','service', 'face', 'account', 'download', 'follower']\n",
    "\n",
    "def remove_redundant_words(text, redundant_phrases):\n",
    "    for phrase in redundant_phrases:\n",
    "        text = re.sub(r'\\b' + re.escape(phrase) + r'\\b', '', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "    \n",
    "tt['reviews_cleaned'] = tt['reviews_no_misspelled_words'].apply(lambda x: remove_redundant_words(x, redundant_phrases))\n",
    "tt.drop(columns=['reviews_no_misspelled_words'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bf7ea-de25-48b7-b826-001065c50b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_string_rows = tt[tt['reviews_cleaned'] == '']\n",
    "\n",
    "print(f\"Number of rows with empty strings: {empty_string_rows.shape[0]}\")\n",
    "\n",
    "tt['reviews_cleaned'] = tt['reviews_cleaned'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2ddb4-9533-452a-a746-f878c131982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.dropna(subset=['reviews_cleaned'])\n",
    "missing_values = tt.isnull().sum()\n",
    "\n",
    "print(tt.shape)\n",
    "print (missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd1c22-9ecf-4951-b384-f93c619db97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt['reviews_tokenize'] = tt['reviews_cleaned'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282851-8467-45ff-ace0-f997b2b493ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "cp = sns.color_palette()\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0485d-76c6-4a96-8ecf-3893670753d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyline=[]\n",
    "for row in tt['reviews_cleaned']:\n",
    "    vs=analyzer.polarity_scores(row)\n",
    "    emptyline.append(vs)\n",
    "    \n",
    "tt_sentiments=pd.DataFrame(emptyline)\n",
    "tt_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740a3d8-628b-4b87-80f6-2f6683ac4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_merged = pd.concat([tt.reset_index(drop=True), tt_sentiments], axis=1)\n",
    "tt_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee86dc8-e4d6-401a-b234-1a5550ed13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_merged.drop(columns=['neg','neu','pos'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0c592-a6c1-490b-954d-22768332eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_merged['Sentiment'] = np.where(\n",
    "    tt_merged['compound'] >= 0.35, 'Positive',\n",
    "    np.where(tt_merged['compound'] <= -0.35 ,'Negative', 'Neutral')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee95d10-f09b-4031-a323-cf7983e0c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Bar Chart, Time(Hour) against Sentiment\n",
    "\n",
    "# Extract the hour from the timestamp\n",
    "tt_merged['hour'] = tt_merged['timestamp'].dt.hour\n",
    "\n",
    "sentiment_over_time_of_day = tt_merged.groupby(['hour', 'Sentiment']).size().unstack()\n",
    "\n",
    "sentiment_over_time_of_day.plot(kind='line', figsize=(10, 6), title=\"Sentiment Distribution by Hour of Day\")\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Review Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69163e-2635-483a-870d-2b9d3ce72d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns deemed as unnecessary\n",
    "tt_merged = tt_merged.drop(columns=['appversion','likes','year_month','compound','timestamp'])\n",
    "tt_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb55b4f-287e-46dc-9aac-517e442a89a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09a1bd-ce28-4d4b-af82-9cb8ee89720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tt_merged.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73904174-8b22-4e0f-b47e-8af3d6f9008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {'positive': 1, 'neutral': 0, 'negative': 2}\n",
    "df['Sentiment_encoded'] = df['Sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ba842-7279-4e66-b0c4-4d3b367f6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preprocess numeric features\n",
    "numeric_features = df[['rating', 'hour']].fillna(0)\n",
    "scaled_numeric = MinMaxScaler().fit_transform(numeric_features)\n",
    "scaled_numeric_df = pd.DataFrame(scaled_numeric, index=numeric_features.index)\n",
    "\n",
    "# 2. Stratified split into train, validation, and test sets\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(\n",
    "    df[['reviews_cleaned', 'reviews_tokenize']],\n",
    "    df['Sentiment_encoded'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=df['Sentiment_encoded']\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_remaining,\n",
    "    y_remaining,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_remaining\n",
    ")\n",
    "\n",
    "# 3. Undersample the positive class in the training set\n",
    "positive_class = X_train[y_train == 1]\n",
    "neutral_class = X_train[y_train == 0]\n",
    "negative_class = X_train[y_train == 2]\n",
    "\n",
    "positive_class_undersampled = positive_class.sample(frac=0.5, random_state=42)\n",
    "X_train_balanced = pd.concat([positive_class_undersampled, neutral_class, negative_class])\n",
    "y_train_balanced = y_train.loc[X_train_balanced.index]\n",
    "\n",
    "# Shuffle the balanced training set\n",
    "X_train_balanced = X_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "y_train_balanced = y_train_balanced.reset_index(drop=True)\n",
    "\n",
    "# 4. Display class distributions in datasets\n",
    "def display_class_distribution(y, dataset_name):\n",
    "    class_counts = y.value_counts()\n",
    "    class_percentage = y.value_counts(normalize=True) * 100\n",
    "    distribution = pd.DataFrame({'Count': class_counts, 'Percentage': class_percentage})\n",
    "    print(f\"\\nClass distribution in the {dataset_name} set:\")\n",
    "    print(distribution)\n",
    "\n",
    "display_class_distribution(y_train_balanced, \"training set after undersampling\")\n",
    "display_class_distribution(y_val, \"validation set\")\n",
    "display_class_distribution(y_test, \"testing set\")\n",
    "\n",
    "# Split ratio calculation\n",
    "total_samples = df.shape[0]\n",
    "train_ratio = X_train.shape[0] / total_samples * 100\n",
    "val_ratio = X_val.shape[0] / total_samples * 100\n",
    "test_ratio = X_test.shape[0] / total_samples * 100\n",
    "\n",
    "print(f\"\\nTraining set ratio: {train_ratio:.2f}%\")\n",
    "print(f\"Validation set ratio: {val_ratio:.2f}%\")\n",
    "print(f\"Testing set ratio: {test_ratio:.2f}%\")\n",
    "\n",
    "# 5. Align numeric features with the split indices and convert to sparse matrices\n",
    "def get_scaled_sparse_features(X, index):\n",
    "    return csr_matrix(scaled_numeric_df.loc[index].values)\n",
    "\n",
    "scaled_train_sparse = get_scaled_sparse_features(X_train, X_train.index)\n",
    "scaled_val_sparse = get_scaled_sparse_features(X_val, X_val.index)\n",
    "scaled_test_sparse = get_scaled_sparse_features(X_test, X_test.index)\n",
    "\n",
    "# 6. TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix_train = vectorizer.fit_transform(X_train['reviews_cleaned'])\n",
    "tfidf_matrix_val = vectorizer.transform(X_val['reviews_cleaned'])\n",
    "tfidf_matrix_test = vectorizer.transform(X_test['reviews_cleaned'])\n",
    "\n",
    "# 7. Combine TF-IDF and numeric features\n",
    "X_train_tfidf = hstack([tfidf_matrix_train, scaled_train_sparse])\n",
    "X_val_tfidf = hstack([tfidf_matrix_val, scaled_val_sparse])\n",
    "X_test_tfidf = hstack([tfidf_matrix_test, scaled_test_sparse])\n",
    "\n",
    "# 8. Validation: Check the shapes and density\n",
    "print(f\"\\nTrain shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Test shape: {X_test_tfidf.shape}\")\n",
    "print(f\"Validation shape: {X_val_tfidf.shape}\")\n",
    "\n",
    "train_density = X_train_tfidf.nnz / (X_train_tfidf.shape[0] * X_train_tfidf.shape[1])\n",
    "print(f\"Train matrix density: {train_density:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ac18f-d786-47c9-8776-689ec46204bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_metrics(y_true, y_pred, y_prob, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    logloss = log_loss(y_true, y_prob)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score (Weighted)\": f1,\n",
    "        \"Log-Loss\": logloss,\n",
    "        \"Precision\": report['weighted avg']['precision'],\n",
    "        \"Recall\": report['weighted avg']['recall']\n",
    "    }\n",
    "\n",
    "def calculate_averages(metrics_dict):\n",
    "    return {metric: np.mean(values) for metric, values in metrics_dict.items()}\n",
    "    \n",
    "def train_and_evaluate_model(model, model_name, kf, X, y):\n",
    "    metrics_dict = {\n",
    "        \"Accuracy\": [],\n",
    "        \"F1-Score (Weighted)\": [],\n",
    "        \"Log-Loss\": [],\n",
    "        \"Precision\": [],\n",
    "        \"Recall\": []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}/{kf.get_n_splits()} - {model_name}\")\n",
    "        \n",
    "        # Split data into train and validation sets\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        # Get probabilities if the model supports predict_proba\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_val_fold)\n",
    "        else:\n",
    "            # Use calibrated probabilities for models like SVM\n",
    "            calibrated_model = CalibratedClassifierCV(model, method='sigmoid', cv='prefit')\n",
    "            calibrated_model.fit(X_train_fold, y_train_fold)\n",
    "            y_prob = calibrated_model.predict_proba(X_val_fold)\n",
    "        \n",
    "        # Collect metrics\n",
    "        metrics = collect_metrics(y_val_fold, y_pred, y_prob, model_name)\n",
    "        \n",
    "        # Append metrics for this fold\n",
    "        for metric, value in metrics.items():\n",
    "            if metric in metrics_dict:\n",
    "                metrics_dict[metric].append(value)\n",
    "        \n",
    "        # Print metrics for this fold\n",
    "        print(f\"{model_name} Accuracy for fold {fold + 1}: {metrics['Accuracy']}\")\n",
    "        print(f\"{model_name} F1-Score for fold {fold + 1}: {metrics['F1-Score (Weighted)']}\")\n",
    "        print(f\"{model_name} Log-Loss for fold {fold + 1}: {metrics['Log-Loss']}\")\n",
    "        print(f\"{model_name} Precision for fold {fold + 1}: {metrics['Precision']}\")\n",
    "        print(f\"{model_name} Recall for fold {fold + 1}: {metrics['Recall']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    averages = calculate_averages(metrics_dict)\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392834a-65e8-459b-b308-50bdfbd01724",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_with_best_params = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        C=16.671739493308188, \n",
    "        max_iter=290, \n",
    "        penalty='l2', \n",
    "        solver='lbfgs', \n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name, model in models_with_best_params.items():\n",
    "    \n",
    "    model_results[model_name] = train_and_evaluate_model(model, model_name, kf, X_train_tfidf, y_train)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a8086-a17e-418e-a76b-8b2ecc3250f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = models_with_best_params['Logistic Regression']\n",
    "\n",
    "y_pred = log_reg_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "log_loss_value = log_loss(y_test, log_reg_model.predict_proba(X_test_tfidf))\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression Test Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "print(f\"Log-Loss: {log_loss_value:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
